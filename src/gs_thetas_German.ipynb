{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "from typing import Iterable\n",
    "\n",
    "from model import LR\n",
    "from data import FairnessDataset, Dataset, SyntheticDataset, GermanDataset, IncomeDataset, GermanPCADataset\n",
    "from ei_effort import Optimal_Effort, PGD_Effort\n",
    "from ei_utils import model_performance, pareto_frontier\n",
    "from ei_model import EIModel, fair_batch_proxy, covariance_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid(center, width, n=15):\n",
    "    if isinstance(width, int) or isinstance(width, float):\n",
    "        width = [width for _ in range(len(center))]\n",
    "    axes = [np.linspace(center[i]-width[i], center[i]+width[i], n) for i in range(len(center))]\n",
    "    grids = np.meshgrid(*axes)\n",
    "    points = np.stack([grid.reshape(-1) for grid in grids]).T\n",
    "    return np.unique(points, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point(thetas):\n",
    "    random_index = np.random.randint(len(thetas))\n",
    "    return thetas[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_result(cache, method, lamb, alpha, total_loss, pred_loss, fair_loss, theta, theta_adv, error):\n",
    "    cache['method'].append(method)\n",
    "    cache['lambda'].append(lamb)\n",
    "    cache['alpha'].append(alpha)\n",
    "    cache['total_loss'].append(total_loss)\n",
    "    cache['pred_loss'].append(pred_loss)\n",
    "    cache['fair_loss'].append(fair_loss)\n",
    "    cache['theta'].append(theta)\n",
    "    cache['theta_adv'].append(theta_adv)\n",
    "    cache['error'].append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PCA1      PCA2\n",
      "0  1.865175  0.563667\n",
      "1  2.124531  2.106108\n",
      "2 -0.716061 -1.760759\n",
      "3 -1.496801  2.673849\n",
      "4  0.101699 -1.301354\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PCAGermanDataset' object has no attribute 'num_feats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m effort \u001b[38;5;241m=\u001b[39m Optimal_Effort(dataset\u001b[38;5;241m.\u001b[39mdelta)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Train, Val, Test Split of Data\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m train_tensors, val_tensors, test_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mnew_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_blind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_blind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m FairnessDataset(\u001b[38;5;241m*\u001b[39mtrain_tensors, new_dataset\u001b[38;5;241m.\u001b[39mimp_feats)\n\u001b[1;32m     36\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m FairnessDataset(\u001b[38;5;241m*\u001b[39mtest_tensors, new_dataset\u001b[38;5;241m.\u001b[39mimp_feats)\n",
      "File \u001b[0;32m~/Documents/Python_projects/EqualImprovability/src/data.py:325\u001b[0m, in \u001b[0;36mPCAGermanDataset.tensor\u001b[0;34m(self, fold, z_blind)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, z_blind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m z_blind:\n\u001b[1;32m    327\u001b[0m         train_tensors \u001b[38;5;241m=\u001b[39m df_to_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_train\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ_train\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/Documents/Python_projects/EqualImprovability/src/data.py:303\u001b[0m, in \u001b[0;36mPCAGermanDataset.split_data\u001b[0;34m(self, fold)\u001b[0m\n\u001b[1;32m    300\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(x_chunks), pd\u001b[38;5;241m.\u001b[39mconcat(y_chunks), pd\u001b[38;5;241m.\u001b[39mconcat(z_chunks), pd\u001b[38;5;241m.\u001b[39mconcat(xz_chunks)\n\u001b[1;32m    302\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m--> 303\u001b[0m train_dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_feats] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(train_dataset[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_feats\u001b[49m])\n\u001b[1;32m    304\u001b[0m train_dataset[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_feats] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(train_dataset[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_feats])\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_feats] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_feats])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCAGermanDataset' object has no attribute 'num_feats'"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "# Instantiate the dataset\n",
    "dataset = GermanPCADataset()\n",
    "\n",
    "delta = dataset.delta\n",
    "z_blind = True\n",
    "tau = 0.5\n",
    "# 1e-7, 0.25, 0.5, 0.75, 1-1e-7\n",
    "# lamb = 1e-7\n",
    "# lamb = .25\n",
    "# lamb = .5\n",
    "lamb = .75\n",
    "# lamb = 1-1e-7\n",
    "alpha = .5\n",
    "proxy = covariance_proxy\n",
    "effort = Optimal_Effort(dataset.delta)\n",
    "\n",
    "# Train, Val, Test Split of Data\n",
    "train_tensors, val_tensors, test_tensors = dataset.tensor(fold=0, z_blind=z_blind)\n",
    "train_dataset = FairnessDataset(*train_tensors, dataset.imp_feats)\n",
    "test_dataset = FairnessDataset(*test_tensors, dataset.imp_feats)\n",
    "\n",
    "# Loss and model definition\n",
    "loss_fn = torch.nn.BCELoss(reduction='mean')\n",
    "model = LR(num_features=train_dataset.X.shape[1])\n",
    "model_adv = LR(num_features=train_dataset.X.shape[1])\n",
    "\n",
    "# Variables to track \n",
    "results = {'method': [], 'lambda': [], 'alpha': [], 'total_loss': [], 'pred_loss': [], 'fair_loss': [], 'theta': [], 'theta_adv': [], 'error': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ei_fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
