{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "from typing import Iterable\n",
    "\n",
    "from model import LR\n",
    "from data import FairnessDataset, Dataset, SyntheticDataset, GermanDataset, IncomeDataset\n",
    "from ei_effort import Optimal_Effort, PGD_Effort\n",
    "from ei_utils import model_performance, pareto_frontier\n",
    "from ei_model import EIModel, fair_batch_proxy, covariance_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid(center, width, n=15):\n",
    "    if isinstance(width, int) or isinstance(width, float):\n",
    "        width = [width for _ in range(len(center))]\n",
    "    axes = [np.linspace(center[i]-width[i], center[i]+width[i], n) for i in range(len(center))]\n",
    "    grids = np.meshgrid(*axes)\n",
    "    points = np.stack([grid.reshape(-1) for grid in grids]).T\n",
    "    return np.unique(points, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_result(cache, method, lamb, alpha, total_loss, pred_loss, fair_loss, theta, theta_adv, error):\n",
    "    cache['method'].append(method)\n",
    "    cache['lambda'].append(lamb)\n",
    "    cache['alpha'].append(alpha)\n",
    "    cache['total_loss'].append(total_loss)\n",
    "    cache['pred_loss'].append(pred_loss)\n",
    "    cache['fair_loss'].append(fair_loss)\n",
    "    cache['theta'].append(theta)\n",
    "    cache['theta_adv'].append(theta_adv)\n",
    "    cache['error'].append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "dataset = SyntheticDataset(num_samples=20000, seed=0)\n",
    "delta = dataset.delta\n",
    "z_blind = True\n",
    "tau = 0.5\n",
    "# 1e-7, 0.25, 0.5, 0.75, 1-1e-7\n",
    "lamb = 0.1\n",
    "alpha = 1.5\n",
    "proxy = covariance_proxy\n",
    "effort = Optimal_Effort(dataset.delta)\n",
    "\n",
    "# Train, Val, Test Split of Data\n",
    "train_tensors, val_tensors, test_tensors = dataset.tensor(fold=0, z_blind=z_blind)\n",
    "train_dataset = FairnessDataset(*train_tensors, dataset.imp_feats)\n",
    "test_dataset = FairnessDataset(*test_tensors, dataset.imp_feats)\n",
    "\n",
    "# Loss and model definition\n",
    "loss_fn = torch.nn.BCELoss(reduction='mean')\n",
    "model = LR(num_features=train_dataset.X.shape[1])\n",
    "model_adv = LR(num_features=train_dataset.X.shape[1])\n",
    "\n",
    "# Variables to track \n",
    "results = {'method': [], 'lambda': [], 'alpha': [], 'total_loss': [], 'pred_loss': [], 'fair_loss': [], 'theta': [], 'theta_adv': [], 'error': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lamb in lambdas:\n",
    "\n",
    "# Generate theta grid\n",
    "thetas = generate_grid(center=[0., 0., 0.,], width=[3., 3., 3.])\n",
    "for i in tqdm.trange(len(thetas), colour='#0091FF'):\n",
    "    theta = thetas[i]\n",
    "    # Set model theta\n",
    "    model = model.set_theta(torch.from_numpy(theta).float())\n",
    "    # Get Y_hat\n",
    "    Y_hat = model(train_dataset.X).reshape(-1)\n",
    "    # Compute prediction loss\n",
    "    pred_loss = loss_fn(Y_hat, train_dataset.Y).detach().float()\n",
    "    \n",
    "    # Get X and Z that received score < 0.5\n",
    "    X_e = train_dataset.X[(Y_hat<tau).reshape(-1)]\n",
    "    Z_e = train_dataset.Z[(Y_hat<tau)]\n",
    "    \n",
    "    # Calculate new X after applying effort to X_e\n",
    "    X_effort = effort(model, train_dataset, X_e)\n",
    "    # Get Y_hat of new X \n",
    "    Y_hat_max = model(X_effort).reshape(-1).detach().float()\n",
    "    # Compute fair loss\n",
    "    fair_loss = proxy(Z_e, Y_hat_max).detach().float()\n",
    "    # Compute total loss\n",
    "    total_loss = ((1-lamb) * pred_loss) + (lamb * fair_loss)\n",
    "    \n",
    "    # Calculate accuracy of model\n",
    "    Y_pred = (Y_hat>=tau)*1\n",
    "    error = 1-np.mean(train_dataset.Y.numpy()==Y_pred.numpy())\n",
    "    \n",
    "    # Track results\n",
    "    cache_result(results, 'EI', lamb, 0., total_loss.item(), pred_loss.item(), fair_loss.item(), theta, theta, error)\n",
    "    \n",
    "    # --- Grid Search to find adversarial theta that maximizes fair loss ---\n",
    "    fair_losses = []\n",
    "    # Generate adversarial theta grid\n",
    "    thetas_adv = generate_grid(center=theta, width=alpha)\n",
    "    for theta_adv in thetas_adv:\n",
    "        # Set adversarial model theta\n",
    "        model_adv = model_adv.set_theta(torch.from_numpy(theta_adv).float())\n",
    "        # Get Y_hat of new X using adversarial theta\n",
    "        Y_hat_max = model_adv(X_effort).reshape(-1)\n",
    "        # Compute fair loss\n",
    "        fair_loss = proxy(Z_e, Y_hat_max).detach().float()\n",
    "        # Append to fair_losses list\n",
    "        fair_losses.append(fair_loss)\n",
    "    \n",
    "    # Find index with largest fair loss\n",
    "    max_i = int(torch.argmax(torch.tensor(fair_losses)))\n",
    "    # Set adversarial theta to the one that yields max fair loss\n",
    "    theta_adv = thetas_adv[max_i]\n",
    "    # Set adversarial model theta\n",
    "    model_adv = model_adv.set_theta(torch.from_numpy(theta_adv).float())\n",
    "    # Get Y_hat of nex X using adversarial theta\n",
    "    Y_hat_max = model_adv(X_effort).reshape(-1)\n",
    "    # Compute fair loss\n",
    "    fair_loss = proxy(Z_e, Y_hat_max).detach().float()\n",
    "    # Compute total loss\n",
    "    total_loss = ((1-lamb) * pred_loss) + (lamb * fair_loss)\n",
    "    \n",
    "    # Uncomment this if you want to see how the fair loss vs theta adv plot\n",
    "    # df_temp = pd.DataFrame({'fair_loss': fair_losses, 'theta_adv': list(map(lambda x: str(x.round(4)), thetas_adv))})\n",
    "    # fig = px.line(df_temp, y='fair_loss', x='theta_adv', markers=True)\n",
    "    # fig.add_hline(y=max(fair_losses))\n",
    "    # fig.show()\n",
    "    \n",
    "    cache_result(results, 'EI', lamb, alpha, total_loss.item(), pred_loss.item(), fair_loss.item(), theta, theta_adv, error)\n",
    "    cache_result(results, 'REI', lamb, alpha, total_loss.item(), pred_loss.item(), fair_loss.item(), theta, theta_adv, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "# Uncomment this if you want to round the lambda\n",
    "# df[['theta', 'theta_adv']] = df[['theta', 'theta_adv']].map(lambda x: x.round(5))\n",
    "\n",
    "df_res = pd.DataFrame()\n",
    "for lamb in df['lambda'].unique():\n",
    "    df_lamb = df[df['lambda']==lamb]\n",
    "    for method in df['method'].unique():\n",
    "        df_md = df_lamb[df_lamb['method']==method]\n",
    "        for alpha in df_md['alpha'].unique():\n",
    "            df_md_a = df_md[df_md['alpha']==alpha]\n",
    "            df_res = pd.concat((df_res, df_md_a.iloc[[int(df_md_a['total_loss'].argmin())]]))\n",
    "df_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
