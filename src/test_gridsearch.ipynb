{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from model import LR\n",
    "from data import FairnessDataset, SyntheticDataset, GermanDataset\n",
    "from ei_effort import Optimal_Effort, PGD_Effort\n",
    "from ei_utils import *\n",
    "from ei_model_dev import FairBatch, Covariance\n",
    "\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = SyntheticDataset(seed=0)\n",
    "dataset = GermanDataset(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training [lambda=0.0000; delta=0.5000]: 100%|\u001b[38;2;0;145;255m██████████\u001b[0m| 100/100 [00:03<00:00, 25.92epochs/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4047, -0.3873,  0.1086, -0.0497, -0.0455,  0.2492,  0.0892, -0.0266,\n",
       "         0.0283,  0.2969, -0.0398, -0.2192, -0.0503, -0.0040, -0.0189,  0.0487,\n",
       "         0.0349,  0.3141,  0.3925, -0.0152,  0.0889])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "train_tensors, val_tensors, test_tensors = dataset.tensor(z_blind=False)\n",
    "train_dataset = FairnessDataset(*train_tensors, dataset.imp_feats)\n",
    "val_dataset = FairnessDataset(*val_tensors, dataset.imp_feats)\n",
    "test_dataset = FairnessDataset(*test_tensors, dataset.imp_feats)\n",
    "\n",
    "# model_params = torch.load('../fc_erm_model.pkl')\n",
    "model = LR(train_dataset.X.shape[1])\n",
    "# model.load_state_dict(model_params)\n",
    "\n",
    "tau = 0.5\n",
    "delta = 0.5\n",
    "# effort_model = Optimal_Effort(delta)\n",
    "effort_model = PGD_Effort(delta, 50)\n",
    "ei_model = Covariance(model, effort_model, tau)\n",
    "ei_model.train(train_dataset, 0.)\n",
    "\n",
    "for module in model.layers:\n",
    "    if hasattr(module, 'weight'):\n",
    "        weights_0 = module.weight.data\n",
    "    if hasattr(module, 'bias'):\n",
    "        bias_0 = module.bias.data\n",
    "\n",
    "theta_0 = torch.cat((weights_0[0], bias_0), 0)\n",
    "theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 21\n",
    "alpha = .1\n",
    "# thetas = torch.from_numpy(generate_grid(theta_0.numpy(), alpha, n=n, ord=np.inf)).float()\n",
    "# thetas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = model(test_dataset.X).reshape(-1).detach().numpy()\n",
    "X = test_dataset.X[(Y_hat<tau),:]\n",
    "Z = test_dataset.Z[(Y_hat<tau)]\n",
    "X_hat_max = effort_model(model, test_dataset, X)\n",
    "\n",
    "losses = []\n",
    "loss_fn = torch.nn.BCELoss(reduction = 'mean')\n",
    "\n",
    "for theta in tqdm(thetas):\n",
    "    weights, bias = theta[:-1].clone().reshape(1, -1), theta[[-1]].clone()\n",
    "\n",
    "    model_adv = deepcopy(model)\n",
    "    for module in model_adv.layers:\n",
    "        if hasattr(module, 'weight'):\n",
    "            module.weight.data = weights.float()\n",
    "        if hasattr(module, 'bias'):\n",
    "            module.bias.data = bias.float()\n",
    "            \n",
    "    Y_hat_max = model_adv(X_hat_max).reshape(-1)\n",
    "    \n",
    "    fair_loss = 0.\n",
    "    # Covariance Proxy\n",
    "    if isinstance(ei_model, Covariance):\n",
    "        fair_loss = torch.square(torch.mean((Z-Z.mean())*Y_hat_max))\n",
    "    # Loss-based Proxy\n",
    "    elif isinstance(ei_model, FairBatch):\n",
    "        loss_mean = loss_fn(Y_hat_max, torch.ones(len(Y_hat_max)))\n",
    "        loss_z = torch.zeros(len(dataset.sensitive_attrs))\n",
    "        for z in test_dataset.sensitive_attrs:\n",
    "            z = int(z)\n",
    "            group_idx = (Z == z)\n",
    "            if group_idx.sum() == 0:\n",
    "                continue\n",
    "            loss_z[z] = loss_fn(Y_hat_max[group_idx], torch.ones(group_idx.sum()))\n",
    "            fair_loss += torch.abs(loss_z[z] - loss_mean)\n",
    "    \n",
    "    losses.append(fair_loss.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_i = np.argmax(losses)\n",
    "fair_loss = losses[max_i]\n",
    "theta_r = thetas[max_i]\n",
    "weights, bias = theta_r[:-1].clone().reshape(1, -1), theta_r[[-1]].clone()\n",
    "\n",
    "model_adv = deepcopy(model)\n",
    "for module in model_adv.layers:\n",
    "    if hasattr(module, 'weight'):\n",
    "        module.weight.data = weights.float()\n",
    "    if hasattr(module, 'bias'):\n",
    "        module.bias.data = bias.float()\n",
    "        \n",
    "X_hat_max = effort_model(model, test_dataset, test_dataset.X)\n",
    "Y_hat_max = model_adv(X_hat_max).reshape(-1).detach().numpy()\n",
    "\n",
    "accuracy, ei_disparity = model_performance(test_dataset.Y.detach().numpy(), test_dataset.Z.detach().numpy(), Y_hat, Y_hat_max, tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = (theta_r-theta_0).abs()\n",
    "print(f'Grid Search Results {\"(Covariance)\" if isinstance(ei_model, Covariance) else \"(Loss-based)\"}')\n",
    "print(f'alpha               |   {alpha}')\n",
    "print(f'Accuracy            |   {accuracy:.5f}')\n",
    "print(f'Fairness Loss       |   {fair_loss:.5f}')\n",
    "print(f'EI Disparity        |   {ei_disparity:.5f}')\n",
    "print(f'theta_0             |   {theta_0}')\n",
    "print(f'theta_r             |   {theta_r}')\n",
    "print(f'alphas              |   {np.round(alphas,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .1\n",
    "pga_Y_hat, pga_Y_hat_max, pga_fair_loss = ei_model.predict(test_dataset, alpha, 1e-7)\n",
    "pga_accuracy, pga_ei_disparity = model_performance(test_dataset.Y.detach().numpy(), test_dataset.Z.detach().numpy(), pga_Y_hat, pga_Y_hat_max, tau)\n",
    "for module in ei_model.model_adv.layers:\n",
    "    if hasattr(module, 'weight'):\n",
    "        pga_weights_r = module.weight.data\n",
    "    if hasattr(module, 'bias'):\n",
    "        pga_bias_r = module.bias.data\n",
    "pga_theta_r = torch.cat((pga_weights_r[0], pga_bias_r), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGA Results (Covariance)\n",
      "alpha               |   0.5\n",
      "Accuracy            |   0.72500\n",
      "Fairness Loss       |   0.01028\n",
      "EI Disparity        |   0.40793\n",
      "alphas              |   tensor([0.2978, 0.3895, 0.5000, 0.1801, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.0000, 0.2580, 0.5000, 0.3411, 0.5000, 0.3209, 0.5000, 0.2774, 0.5000,\n",
      "        0.0000, 0.5000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "alphas = (pga_theta_r-theta_0).abs()\n",
    "print(f'PGA Results {\"(Covariance)\" if isinstance(ei_model, Covariance) else \"(Loss-based)\"}')\n",
    "print(f'alpha               |   {alpha}')\n",
    "print(f'Accuracy            |   {pga_accuracy:.5f}')\n",
    "print(f'Fairness Loss       |   {pga_fair_loss:.5f}')\n",
    "print(f'EI Disparity        |   {pga_ei_disparity:.5f}')\n",
    "# print(f'theta_0             |   {np.round(theta_0, 4)}')\n",
    "# print(f'theta_r             |   {np.round(pga_theta_r, 4)}')\n",
    "print(f'alphas              |   {np.round(alphas,4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
